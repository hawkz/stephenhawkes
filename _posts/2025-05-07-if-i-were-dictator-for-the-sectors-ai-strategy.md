---
published: true
date: 2025-05-07
title: If I Were Dictator for the Sector’s AI Strategy
summary: Dictatorship is sadly on the rise, but if I was a benevolent dictator,
  what would I do for the sector? And why the free legal advice sector gave me
  hope
categories: blog
---
Yesterday I took part in a roundtable focused on the future of free legal advice, and I left inspired. The conversation centred on something simple but powerful: how we coordinate our work around AI and tech to better serve frontline organisations. Not to invent more tools, but to create the scaffolding that helps people use the ones we've already built.

It reminded me how much more we could do—if we weren’t scattered. That then sparked with the constant barrage of the current news cycle, leading to me pondering:

> "If I had the power to dictate the social sector’s AI response—to unify, not control—what would I _actually_ do?"

Here’s my manifesto.

## **We Need Radical Coherence, Not More Tools**

This is not about accelerating adoption. It’s about slowing down to align. Right now, the sector is full of energy, experiments, and well-intentioned pilots. But we lack shared scaffolding. We duplicate. We chase shiny tools. We let hype outrun purpose.

So, in this thought experiment, I’m your benevolent dictator. Not forever—just long enough to lay the groundwork. (That's what they all say, right?!!)

### **1\. Start with Doctrine, Not Technology. Dictators use situational awareness.**

Every organisation would adopt [Wardley Doctrine Phase 1](https://learnwardleymapping.com/doctrine/) as the baseline.

That means:

*   We stop starting with solutions.
    
*   We invest in situational awareness.
    
*   We act only when we understand user needs, inertia, and strategic play.
    

Most AI projects will fail not because the tech is wrong, but because the thinking is shallow. Phase 1 doctrine makes that failure harder to repeat.

### **2\. Open IP, Always - Be Transparent**

If you build a tool for the public good, the public should be able to inspect it.

No locked-in models. No secret sauce. No proprietary infrastructure acting as a middleman between vulnerable people and critical services... and no extractive profiteering from sector need.

This isn't idealism. It’s trust, audit-ability, and collaboration. We can’t build sector-wide confidence on black-box systems.

### **3\. Procurement as a Strategic Filter (Ethical DOGE or DOGS "The department of governing sustainably")**

We don’t need 40 chatbots doing the same half-useful thing. We need a filter that:

*   **Funds only projects aligned with doctrine**
    
*   **Prioritises reuse and interoperability**
    
*   **Denies duplication unless clearly justified**
    

Controlling procurement is really at the heart of sector logic, so it makes sense to think about the upsides. In this dictatorship, funding is tied to strategic clarity. No doctrine, no money.

And here’s the kicker:

**Funders must invest in a shared infrastructure** that:

*   Tracks what’s already been funded, sharing standardised data.
    
*   Signals available tools and resources, they run the knowledge-base of what exists as signposts when duplication is requested.
    
*   Acts as a coordination layer, not a bottleneck
    

This is the memory the sector currently lacks. The funders have the power and resources, so we need that weilded toward solution. Unlike a dictatorship or oligarchy funders are independent, so shared data standards will give a massive win to all of them. It doesn't have to be complex: "is this already funded?" and a list of past grantees and providers comes back.

### **4\. Know Users and Their Needs by Actually Listening**

AI isn’t strategy. It’s just a tool.  
If we’re not solving real problems—triage, reporting, data entry, referrals—we’re wasting time.

This means:

*   We embed researchers inside services.
    
*   We stop building tools in isolation. Cohorts are better than solo funded orgs.
    
*   We put the painful, messy, brilliant frontline work at the centre.
    

Design is co-created. Feedback is continuous. Value is real.

### **5\. Train People, Not Just Models - Common language**

Too much AI literacy is abstract. We're being an AI project is like saying we're building a software project, and unchecked will drive duplication. We can use [Wardley mapping](https://learnwardleymapping.com/) here to break down systems and have better conversations, but also have courses like [CAST's AI first step](https://www.wearecast.org.uk/our-work/free-digital-resources/getting-started-with-ai-a-free-self-serve-course/) learned by all.

So we start from plain language.

*   Everyone moves from jargon to terms they understand to the next level of detail.
    
*   Everyone learns to map. [It only takes a few minutes](https://learnwardleymapping.com/).
    
*   Therefore everyone can spot tech theatre.
    
*   Everyone—from caseworkers to commissioners—gets the tools to challenge bad implementations and steer better ones.
    

We don’t build AI capacity with PDFs. We do it with shared language and practical exposure.

### **The Sector Already Gets This—We Just Haven’t Joined It Up Yet**

That roundtable I attended? It’s already happening:

*   Legal advice networks naming their needs.
    
*   Funders wanting to coordinate better, calling for data standards.
    
*   Initiatives trying to collate and centralise support.
    
*   Whiteboards filled with ideas for sharing what works and what doesn’t.
    

The question isn’t “should we do this?” It’s “how quickly and urgently can we align around doing it together?”

### **It's good that I'm not a dictator...**

I don’t want control. I want alignment because the waste is heart-breaking to watch. We all know dictatorship is not the right way to govern, but seeing the frustration and hunger in the room yesterday for a cohesive strategy really gave me something to think though. Shared doctrine. Open systems. Co-ordinated funding. User-led tools. Plain language. This is what we know, lets hopefully not let a two letter term trip us up and instead use it to create radical coherence.

## Long live the rebellion